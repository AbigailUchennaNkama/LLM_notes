{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "my_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic\n",
    "\n",
    "client = Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_models = [\"claude-3-5-sonnet-20240620\",\"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    our_first_message = client.messages.create(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(our_first_message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Erlaubnis\" is a German word that translates to \"permission\" in English.\n",
      "\n",
      "For example:\n",
      "- \"Ich brauche Ihre Erlaubnis, um das zu tun.\" translates to \"I need your permission to do that.\"\n",
      "- \"Sie hat die Erlaubnis, das Auto zu fahren.\" translates to \"She has permission to drive the car.\"\n"
     ]
    }
   ],
   "source": [
    "def translate(word, language):\n",
    "    response = client.messages.create(\n",
    "        model = \"claude-3-opus-20240229\",\n",
    "        max_tokens= 500,\n",
    "        messages=[{\"role\":\"user\", \"content\":f\"translate {word} into {language}\"}]\n",
    "    )\n",
    "    print(response.content[0].text)\n",
    "    #return response.content[0].text\n",
    "\n",
    "translate(\"erlaubnis\", \"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'API_KEY' (str)\n",
      "Stored 'MODEL_NAME' (str)\n"
     ]
    }
   ],
   "source": [
    "API_KEY = \"my_api_key\"\n",
    "MODEL_NAME = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# Stores the API_KEY & MODEL_NAME variables for use across notebooks within the IPython store\n",
    "%store API_KEY\n",
    "%store MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some critical thinking questions to further explore why the sky is blue:\n",
      "\n",
      "- What causes the sky to appear blue in color?\n",
      "- How does the composition of the Earth's atmosphere contribute to the sky's blue appearance?\n",
      "- What role do the wavelengths of visible light play in the sky's blue hue?\n",
      "- How do atmospheric gases and particles interact with sunlight to create the blue sky?\n",
      "- What other factors, such as the time of day or weather conditions, can affect the sky's color?\n",
      "- How have scientists historically explained and studied the phenomenon of the blue sky?\n",
      "- What are some alternative perspectives or theories that have been proposed to explain the sky's blueness?\n",
      "\n",
      "By exploring these types of questions, we can delve deeper into the scientific principles and mechanisms behind the familiar blue color of the sky. Let me know if you have any other thoughts or reflections on this topic.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# System prompt\n",
    "SYSTEM_PROMPT = \"Your answer should always be a series of critical thinking questions that further the conversation (do not provide answers to your questions). Do not actually answer the user question.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Why is the sky blue?\"\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 2, 3.\n",
      "\n",
      "--------------------------- GRADING ---------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Prompt - this is the only field you should change\n",
    "PROMPT = \"Please count numerically from one to three\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    pattern = re.compile(r'^(?=.*1)(?=.*2)(?=.*3).*$', re.DOTALL)\n",
    "    return bool(pattern.match(text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*giggles* The sky is SOOO big! It's bigger than anything! You can't even see the end of it! It's like a big blue blanket that covers the whole world! *waves arms around* It's so big, I can't even reach it! *jumps up and down* Wheee!\n",
      "\n",
      "--------------------------- GRADING ---------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "# System prompt - this is the only field you should change\n",
    "SYSTEM_PROMPT = \"You should respond like a 3-year-old.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"How big is the sky?\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    return bool(re.search(r\"giggles\", text) or re.search(r\"soo\", text))\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Write a haiku about robots.\"\n",
    "\n",
    "# improved Prompt\n",
    "More_Specific_PROMPT = \"Write a haiku about robots. Skip the preamble; go straight into the poem.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Who is the best basketball player of all time?\"\n",
    "\n",
    "# improved Prompt\n",
    "More_Specific_PROMPT = \"Who is the best basketball player of all time? Yes, there are differing opinions, but if you absolutely had to pick one player, who would it be?\"\n",
    "\n",
    "# Prompt to write a story of longer than 800 words\n",
    "PROMPT = \"write a funny story about animals. Your response should be more than 800 words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prom to write a story of longer than 800 words\n",
    "PROMPT = \"write a funny story about animals. Your response should be more than 800 words\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt without role prompting\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Prompt with role prompting using system prompt.\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "I will tell you the name of an animal. Please respond with the noise that animal makes. Cow\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "Moo.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variable content\n",
    "ANIMAL = \"Cow\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"I will tell you the name of an animal. Please respond with the noise that animal makes. {ANIMAL}\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Yo Claude. Show up at 6am tomorrow because I'm the CEO and I say so. <----- Make this email more polite but don't change anything else about it.\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "Dear Claude,\n",
      "\n",
      "I hope this email finds you well. As the CEO, I would like to request your presence at 6 am tomorrow. I understand this may be an early start, but I believe it is necessary for the success of our company. Please let me know if this time works for you, and I appreciate your cooperation.\n",
      "\n",
      "Thank you,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Yo Claude. {EMAIL} <----- Make this email more polite but don't change anything else about it.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Yo Claude. <tag>Show up at 6am tomorrow because I'm the CEO and I say so.</tag> <----- Make this email more polite but don't change anything else about it.\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "Dear [Your Name],\n",
      "\n",
      "I hope this email finds you well. I wanted to kindly request your presence at our office tomorrow at 6 am. As the CEO, I would greatly appreciate your attendance at this time.\n",
      "\n",
      "Thank you for your understanding and cooperation.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "EMAIL = \"Show up at 6am tomorrow because I'm the CEO and I say so.\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Yo Claude. <tag>{EMAIL}</tag> <----- Make this email more polite but don't change anything else about it.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "Please write a haiku about Rabbit. Put it in  tags.\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "Here is a haiku about Rabbit, enclosed in tags:\n",
      "\n",
      "<haiku>\n",
      "Fluffy, twitching nose,\n",
      "Hopping through the verdant field,\n",
      "Rabbit's gentle grace.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Rabbit\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in  tags.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(PROMPT)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New argument added for prefill text, with a default value of an empty string\n",
    "def get_completion(prompt: str, system_prompt=\"\", prefill=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt},\n",
    "          {\"role\": \"assistant\", \"content\": prefill}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN:\n",
      "Please write a haiku about Cat. Put it in  tags.\n",
      "\n",
      "ASSISTANT TURN:\n",
      "\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "Here is a haiku about a cat, enclosed in tags:\n",
      "\n",
      "<haiku>\n",
      "Feline grace and poise,\n",
      "Purring softly by the fire,\n",
      "Watchful eyes observe.\n",
      "</haiku>\n"
     ]
    }
   ],
   "source": [
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Put it in  tags.\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN:\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN:\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------- Full prompt with variable substutions ---------------------------\n",
      "USER TURN\n",
      "Please write a haiku about Cat. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\".\n",
      "\n",
      "ASSISTANT TURN\n",
      "{\n",
      "\n",
      "------------------------------------- Claude's response -------------------------------------\n",
      "{\n",
      "  \"first_line\": \"Feline grace and poise,\",\n",
      "  \"second_line\": \"Purring softly by my side,\",\n",
      "  \"third_line\": \"Captivating cat.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Variable content\n",
    "ANIMAL = \"Cat\"\n",
    "\n",
    "# Prompt template with a placeholder for the variable content\n",
    "PROMPT = f\"Please write a haiku about {ANIMAL}. Use JSON format with the keys as \\\"first_line\\\", \\\"second_line\\\", and \\\"third_line\\\".\"\n",
    "\n",
    "# Prefill for Claude's response\n",
    "PREFILL = \"{\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "print(\"USER TURN\")\n",
    "print(PROMPT)\n",
    "print(\"\\nASSISTANT TURN\")\n",
    "print(PREFILL)\n",
    "print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
    "print(PREFILL + get_completion(PROMPT, prefill=PREFILL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmMath",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
